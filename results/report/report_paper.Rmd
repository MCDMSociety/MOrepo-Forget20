---
title: "Computational results (preliminary version)"
description: |
  This report is a preliminary version of the computational results included in the paper
author:
  - name: Nicolas Forget
    url: http://pure.au.dk/portal/en/nforget@econ.au.dk
    affiliation: CORAL, BSS, Aarhus University
    affiliation_url: https://econ.au.dk/coral
  - name: Lars Relund Nielsen
    url: http://pure.au.dk/portal/en/larsrn@econ.au.dk
    affiliation: CORAL, BSS, Aarhus University
    affiliation_url: https://econ.au.dk/coral
  - name: Sune Lauth Gadegaard
    url: http://pure.au.dk/portal/en/sgadegaard@econ.au.dk
    affiliation: CORAL, BSS, Aarhus University
    affiliation_url: https://econ.au.dk/coral
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
bibliography: references.bib
citation_url: https://mcdmsociety.github.io/MOrepo-Forget20/report_paper.html
---

<style type="text/css">
table td, table th {  /* Table  */
  font-size: 10px !important;
}
</style>

```{r setup, include=FALSE}
#' Function for loading missing packages that install them if not already installed.
#'
#' @param packages String vector with package names
#'
#' @return NULL (invisible)
#' @export
#'
#' @examples loadPackages(c("MASS", "ggplot2", "tikzDevice"))
loadPackages <- function(packages) {
  newP <- packages[!(packages %in% installed.packages()[,"Package"])]
  if(length(newP)) install.packages(newP, repos = "http://cran.rstudio.com/")
  lapply(packages, library, character.only = TRUE)
  invisible(NULL)
}
loadPackages(c("tidyverse", "knitr", "rgl", "gMOIP", "rmarkdown", "ggplot2", "plotly", "DT", "RColorBrewer", "wesanderson", "kableExtra"))

if (isTRUE(getOption('knitr.in.progress'))) options(rgl.useNULL=TRUE)
rgl::setupKnitr()
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning=FALSE, message=FALSE, include = TRUE, 
  # cache = TRUE, autodep = TRUE,
  echo=FALSE,
  out.width = "99%", fig.width = 8, fig.align = "center", fig.asp = 0.7,
  layout="l-page"   #"l-screen-inset"
)
knit_hooks$set(webgl = hook_webgl, rgl = hook_rgl)
options(knitr.kable.NA = '')
```

*This report is a preliminary version of the computational results included in the paper. Only instances generated with option spheredown are used since they seems to be hard instances.*

<!-- See https://rstudio.github.io/distill/ on how to write this report. -->

In this section we report on the computational experiments conducted with the tri–objective
branch–and–bound algorithm. 

All instances are converted to minimization problems meaning that if an objective function $z(x)$ should be maximized, we minimize $−z(x)$ instead. 

The purpose of the computational study is to answer the following questions:
  
<!--[Just some ideas for the moment. Add/modify as you like]  -->
  
  1) What is the performance of the different algorithm configurations and which configurations perform the best ? In particular, is it worth doing objective branching ?
  1) Why does objective branching perform as it does ?
  1) How is the performance of the tri-objective B&B algorithm compared to objective space search algorithms?
  
  <!-- 1) How do node selection, (variable selection) and objective branching affect the performance of the algorithm?
  1) In which subprocedures are the cpu time used?
  1) How are nodes pruned?
  1) Where in the tree do we use obj branching avg + min and max values (relative values and box plot)?
  1) Depth of tree in AP vs KP?
  1) Do integer rounding improve the performance? -->
  
  
  
<!--  Statistic: Number of nodes in the tree relative to total possible given depth -->
  
<!--  [Only focus on mof variable sel] -->

<!-- ### Old questions -->
<!-- We first consider  -->

<!--   2. Which instances are hard to solve? -->
<!--      a) What is the cpu for each instance? -->
<!--      b) Which sphere generation instances are hardest to solve? -->
<!--      c) What is the std.dev. within each instance group? -->
<!--      d) In which subprocedures are the cpu time used? -->

<!--   3. Which algorithm configuration is best? -->
<!--      a) Is there a clear winner? -->
<!--      b) Is the best node selection strategy affected by other algorithm configurations? -->
<!--         * Are some problem classes solved best with one node selection strategy compared to others? -->
<!--         * Are 'easy' problems solved best with one node selection strategy compared to others? -->
<!--      c) Does different `OB` strategies affect the node selection strategy? -->

<!--   4. How are nodes pruned? -->

# Impelmentation details and algorithm configurations

All algorithms have been implemented in Julia $1.0.1$. The experiments was done a computer with an Intel(R) Core(TM) i7-4785T CPU @ 2.20GHz processor and 16GB of RAM memory, using Linux Ubuntu 14.04 LTS.

In order to compute the linear relaxation at each node, the solver [Bensolve](https://www.optimierung-loehne.uni-jena.de/bensolve) is used [@Bensolve]. To avoid reading from and writing to text files at each node of the tree, we have implemented a wrapper that calls Bensolve, retrieve some outputs and insert them directly in our code as matrices. 
Numerical instabilities leading to missing non-dominated points in the final output have been detected while building the hyperplanes representation of the lower bound set. The matrix used when finding the normal to each hyperplane may in a few cases be close to singular (its determinant is close to zero). Hence a small value `eps` has been introduced so that if the determinant is less than or equal `eps`, then the hyperplane is discarded, thus leaving a weaker but valid lower bound set. For more information, we refer the reader to the [section about numerical instabilities](https://mcdmsociety.github.io/MOrepo-Forget20/report.html#numerical-instablities) in @Forget20a. We have used `eps` $= 0.001$ in all tests reported in this paper resulting in that no missing non-dominated points have been detected.

The variable selected in Step 5 of the algorithm differs depending on whether objective branching is applied or not. If no objective branching is performed, the algorithm will branch on the free variable that is the most often fractional among the extreme points of the lower bound set, given that at least one of the variables has a fractional value. If no variable has a fractional value in any of the extreme points, the variable that is the most often different (i.e. with the average value closest to $0.5$) is chosen. If objective branching is enabled, the rule is the same, except that a different variable may be chosen in each sub-problem. Indeed, given a sub-problem $P(\eta,s)$ in the objective space, only the extreme points of the lower bound set included in $P(\eta,s)$ (i.e. that dominates $s$) will be considered. In case there are multiple possible choices or no extreme point included in $P(\eta,s)$, the variable with the smallest index will be chosen.

To test different algorithm configurations we use the following parameters:

* `nS` denotes the node selection method (Step 1 of Algorithm 1). Two values are possible:
  + `B`: breadth first strategy.
  + `D`: depth first strategy.
* `oB` denotes the objective branching strategy. Three configurations are tested:
  + `N`: no objective branching is performed. This is the equivalent of skipping Step 4 of Algorithm 1. 
  + `E`: exact objective branching using super local upper bounds (see Algorithm 2). [LRN: Should we call it full OB?]
  + `C`: objective branching using a single cone, namely, the nadir point of $D(\eta)$ (see Section 4.3).

This leads to 6 configurations: `B|N`, `B|E`, `B|C`, `D|N`, `D|E` and `D|C`. For an overview of more configurations such as different variable selection rules (Step 5 of the algorithm), the reader is referred to @Forget20a.

<!-- * Branching scheme (`none`, `exact`, `cone`): in a regular branch and bound, branching is operated (i.e. sub-problems are created) in the decision space. In the bi-objective case, it has been shown that creating additional sub-problems in the objective space (procedure called objective branching in this study) leads to better computational times. Three versions of the branch and bound will be tested: -->

<!--   + None: no objective branching is performed. Hence, this version is just a regular branch and bound. -->

<!--   + exact: objective branching is performed using the algorithm from [master thesis paper]. -->

<!--   + unique cone: a unique sub-problem is created at each node. In this case, objective branching is applied on the nadir point of the local upper bounds dominated by the lower bound set. See [master thesis paper] for more details. -->



# Test instances

```{r load instance results}
toLink <- function(inst) {
  if (length(inst) == 0) return("")
  links <- str_c('../../docs/instances/', inst, '.html')
  url <- str_c('instances/', inst, '.html')
  if_else(file.exists(links), str_c('<a href="', url, '">', inst, '</a>'), inst)
}

limSec <- c(0, 30*60)  # computation time limits (exclude instances with max cpu < limSec[1] or  min cpu > limSec[2])
abbrv <- function(str) {
  str_replace_all(str, 
    c("breadth" = "B", "depth" = "D", "mof" = "F", "mfavg" = "A", "exact" = "E", 
      "cone" = "C", "none" = "N", "None" = "N", "spheredown" = "down", "sphereup" = "up"))
}
datAll <- read_csv("../statistics.csv") %>%   #"../convert/data/stat.csv"
  filter(coef == "spheredown", rangeC == "[1,1000]" | rangeC == "[1,1000]|[1,100]", varsel == "mof") %>% #| coef == "sphereup"
  mutate(YNsRatio = YNs/YN, 
         YNusRatio = 1-YNs/YN, 
         YNsneRatio = (YNs-YNse)/YN,
         algConfig = tolower(str_c(nodesel, varsel, OB, sep="|")),
         nodeselVarsel = tolower(str_c(nodesel, sep="|")),   #nodeselVarsel = tolower(str_c(nodesel, varsel, sep="|")),
         resultName = str_c(instance, algConfig, sep="_")) %>% 
  mutate(algConfig = tolower(str_c(nodesel, OB, sep="|")))
  # group_by(instance) %>% 
  # mutate(minCpu = min(tpstotal), maxCpu = max(tpstotal)) %>% 
  # mutate(unsolvedAllConfigs = if_else(maxCpu < limSec[1] | minCpu >= limSec[2], T, F))
algConfigsN <- length(unique(datAll$algConfig))

# tmp <- datAll %>% 
#   group_by(instance) %>% 
#   summarise(minCpu = min(tpstotal), maxCpu = max(tpstotal)) %>% 
#   filter(maxCpu < limSec[1] | minCpu > limSec[2]) %>% 
#   pull(instance)

tmp <- datAll %>% 
  group_by(pb, n, coef) %>% 
  mutate(allUnsolved = 1 - max(solved)) %>% 
  ungroup() %>% 
  filter(allUnsolved == 1) %>% 
  pull(instance)

datAll <- datAll %>% 
  filter(!(instance %in% tmp)) %>%
  mutate(solved = if_else(tpstotal >= limSec[2] | solved == 0, 0, 1)) %>% 
  # group_by(instance) %>% 
  # filter(n() == algConfigsN) %>% 
  # ungroup() %>% 
  mutate(tpstotal = if_else(tpstotal >= limSec[2], limSec[2], tpstotal),
         algConfig = abbrv(algConfig),
         coef = abbrv(coef),
         nodeselVarsel = abbrv(nodeselVarsel),
         OB = abbrv(OB))
# View(datAll %>% group_by(instance) %>% summarise(ctr = n()))
algConfigs <- unique(datAll$algConfig)
nodeselVarselConfigs <- unique(datAll$nodeselVarsel)
datNotSolved <- datAll %>% filter(solved == 0) 
datSolved <- datAll %>% filter(solved == 1)
datInput <- datAll %>% 
  group_by(instance) %>%
  mutate(unsolved = 1-max(solved)) %>%
  ungroup() %>%
  distinct(instance, .keep_all = TRUE) %>% 
  select(instance, pb, n, p, coef, contains("range"), ratioNDcoef, unsolved)
# instances with all configs run

datWin <- 
  datAll %>% 
  group_by(instance) %>% 
  nest() %>% 
  mutate(data = map(data, function(df) {df %>% arrange(tpstotal) %>% slice(1)})) %>% 
  mutate(win = map(data, function(df) {df$algConfig})) %>% 
  unnest(c(win, data)) 

datNotStable <- read_csv("../convert/data/stat.csv", col_types = cols()) %>%
  filter(coef == "spheredown", rangemax == 1000, solved == 1) %>% #| coef == "sphereup"
  group_by(instance) %>%
  distinct(YN) %>%
  summarise(ctr = n()) %>%
  dplyr::filter(ctr > 1)
if (nrow(datNotStable) > 0) stop("Instabilities found!")

datObNC <- datAll %>% filter(OB == "N" | OB == "C")

tmp <- tibble(algConfig = datAll %>% pull(algConfig) %>% unique()) %>% separate(algConfig, c("nodeselVarsel", "OB"), remove = F, sep = "\\|")
datAllJoined <- datAll %>% 
  group_by(instance) %>% 
  nest() %>% 
  mutate(missing = map(data, function(df) full_join(df, tmp, by = c("algConfig", "nodeselVarsel", "OB")) %>% mutate(pb = df$pb[1]))) %>% 
  select(-data) %>% 
  unnest(missing) %>% 
  replace_na(list(tpstotal = 1800)) 
```

```{r Define color scales}
# display.brewer.pal(n = 11, name = "RdYlBu")
pal <- brewer.pal(n = 11, name = "RdYlBu")
# algConfigs <- algConfigs[c(2,5, 3,6, 1,4, 8,11, 9,12, 7,10)]
palAlgConfigs <- wes_palette("Zissou1", algConfigsN, type = "continuous")
palAlgConfigs <- c(brewer.pal(n =  algConfigsN/2, name = "Reds"), brewer.pal(n =  algConfigsN/2, name = "Blues"))
# display.brewer.pal(n = 9, name = "Blues")
# brewer.pal(n = 6, name = "Greens")

scale_color_algConfig <- scale_color_manual(
  values = setNames(palAlgConfigs, algConfigs),
  drop = F)
scale_fill_algConfig <- scale_fill_manual(
  values = setNames(palAlgConfigs, algConfigs),
  drop = F)

scale_color_nodesel_varsel <- scale_color_manual(
  values = setNames(pal[c(1,3,9,11)], nodeselVarselConfigs),
  drop = F)

scale_color_ob <- scale_color_manual(
  values = setNames(pal[c(1,3,9,11)], c("breadth", "depth")),
  drop = F)

scale_fill_ob <- scale_fill_manual(
  values = setNames(pal[c(1,3,9,11)], c("breadth", "depth")),
  drop = F)

scale_color_nodesel <- scale_color_manual(
  values = c("breadth" = "red", "depth" = "green"),
  drop = F)

scale_alpha_varsel <- scale_alpha_manual(
  values = c("mof" = 1, "mfavg" = 0.75),
  drop = F)

scale_linetype_valsel <- scale_linetype_manual(
  values = c("mof" = 1, "mfavg" = 2),
  drop = F)
  
scale_linetype_ob <- scale_linetype_manual(
  values = c("cone" = 1, "exact" = 2, "None" = 3, "C" = 1, "E" = 2, "N" = 3),
  drop = F)

scale_linetype_nodesel_varsel <- scale_linetype_manual(
  values = c("cone" = 1, "exact" = 2, "None" = 3, "C" = 1, "E" = 2, "N" = 3, "B" = 1, "D" = 2),
  drop = F)
```

```{r tabInput, layout="l-screen-inset",}
tabInput <- datInput %>% 
  group_by(pb, n, coef) %>% 
  summarise(instances = n(), 
            rangeCoef = rangeC[1], 
            gapO = mean(c(rangeGapZ1, rangeGapZ2, rangeGapZ3)), 
            ratioNDCoef = mean(ratioNDcoef), 
            someUnsolved = max(unsolved)) %>% 
  ungroup() %>% 
  group_by(pb) %>% 
  summarise(n = str_c(n, collapse = ", "), 
            instances = mean(instances), 
            range = rangeCoef[1], ratio = mean(ratioNDCoef)
            ) 
  # mutate(n = str_c(n, if_else(someUnsolved == 1, "*", "")))
# tabInput %>% 
#   select(-pb, -coef, -someUnsolved, -gapO, -rangeCoef, -ratioNDCoef) %>%
#   kable(digits = c(0,0), col.names = c("$n$", "#"),
#         caption = "Instances used ($n$: number of variables, #: number of instances.") %>% 
#   kable_styling(full_width = T) %>% 
#   pack_rows("AP", min(which(tabInput$pb == "AP")), max(which(tabInput$pb == "AP"))) %>% 
#   pack_rows("KP", min(which(tabInput$pb == "KP")), max(which(tabInput$pb == "KP"))) %>% 
#   pack_rows("UFLP", min(which(tabInput$pb == "UFLP")), max(which(tabInput$pb == "UFLP"))) 

tabInput %>% 
  select(-range, -ratio) %>% 
  group_by(pb) %>% 
  kable(digits = c(0,0,1), col.names = c("", "$n$", "#"),
        caption = "Instances used ($n$: number of variables, #: number of instances given variable size).") %>% 
  kable_styling(full_width = T) 
```

A total of `r nrow(datInput)` instances (see Table \@ref(tab:tabInput)) has been generated. Three problem classes are considered: the linear assignment problem (AP), the knapsack problem (KP) and the uncapacitated facility location problem (UFLP). The mathematical programming formulation for each problem is given in the appendix. The number of variables in each problem class has been increased until no algorithm configurations was able to compute an exact solution within a time limit of half an hour (1800 seconds).

The objective coefficients are generated in the range [1, 1000] on the lower part of a 3D sphere using the R package @gMOIP. Hence a high number of the coefficient vectors for the variables are non-dominated among each other (`r round(100 * tabInput %>% filter(pb == "AP") %>% pull(ratio))`% for AP and `r round(100 * tabInput %>% filter(pb == "KP") %>% pull(ratio))`% for KP). This way of generating the objective coefficients has been tested against other methods and seems to result in solutions with a high number of non-dominated points [@Forget20a] (implying hard instances). For UFLP instances the same generation method has been used. However, since two cost groups exists (see the appendix), a range of [1, 1000] has been used for generating the cost of assigning a customer to a service point and a range of [1, 100] for generating the cost for opening a service point. The objective coefficients are all integer.

For the AP the constraints are fixed given the problem size. The same holds for the UFLP when assuming the number of facilities equals the number of customers. For KP instances, the integer coefficients of the constraint are generated randomly in the range [1,15]. The right-hand side is set equal to half of the sum of the coefficients on the right hand side [LRN: Rounded???]. For KP three different constraints are generated for each variable size and objective coefficients.


<!-- # Output statistics -->

<!-- The following statistics will be considered: -->

<!-- * `cpu`: total CPU time expressed in seconds used to solve an instance with a given configuration -->
<!-- * `|YN|`: size of $\mathcal{Y}_N$, i.e. the number of non-dominated points which can be partitioned into -->
<!--   + `se`: number of supported extreme points, -->
<!--   + `sne`: number of supported non-extreme points, -->
<!--   + `us`: number of unsupported points. -->
<!-- * `node`: number of nodes explored in the branching tree when solving an instance with a given configuration -->
<!-- * `prune`: how leaf nodes are pruned partitioned into  -->
<!--   + `I`: number of leaf nodes pruned by infeasibility, -->
<!--   + `O`: number of leaf nodes pruned by optimality, -->
<!--   + `D`: number of leaf nodes pruned by dominance. [SLG: D also used for depth first] -->
  
All algorithm configurations have been tested using a time limit of half an hour (1800 seconds).



<!-- For each algorithm run we have the following statistics: -->

<!-- ```{r instance output, eval = FALSE} -->
<!-- datOutput <- datAll #%>% select(instance, nodesel:maxnbpbOB) -->
<!-- datOutput -->
<!-- ``` -->

<!--   - `solved`: 1 if the instance is solved within 3600 sec, 0 otherwise. -->
<!--   - `YN`: size of YN. If `solved` = 0, it represent the size of the upper bound set at 3600 sec, when the algorithm stops. -->
<!--   - `YNse`: Number of supported extreme nondominated points. -->
<!--   - `YNs`: Number of supported nondominated points. -->
<!--   - `YNsRatio`: Ratio of supported nondominated points. -->
<!--   - `YNusRatio`: Ratio of unsupported nondominated points. -->
<!--   - `YNsneRatio`: Ratio of supported non-extreme nondominated points. -->
<!--   - `nbnodes`: number of nodes explored. -->
<!--   - `mindepthT`: minimal depth of a leaf node. -->
<!--   - `maxdepthT`: maximal depth of a leaf node (and thus of the tree). -->
<!--   - `avgdepthT`: average depth of the leaf nodes. -->
<!--   - `avgdepthYN`: average depth of the nodes where the non-dominated points were found. -->
<!--   - `nbleaf`: number of leaf nodes. -->
<!--   - `nbinfeas`: number of nodes pruned by infeasibility. -->
<!--   - `pctinfeas`: proportion (in %) of leaf nodes pruned by infeasibility. -->
<!--   - `tpsinfeas`: average time spend to prune a node by infeasibility (in msec). -->
<!--   - `nbopt`: number of nodes pruned by optimality. -->
<!--   - `pctopt`: proportion (in %) of leaf nodes pruned by optimality. -->
<!--   - `tpsopt`: average time spend to prune a node by optimality (in msec). -->
<!--   - `nbdomi`: number of nodes pruned by dominance. -->
<!--   - `pctdomi`: proportion (in %) of leaf nodes pruned by dominance. -->
<!--   - `avgdomi`: average time spend to prune a node by dominance (in msec). -->
<!--   - `nbLB`: number of lower bound set computed. -->
<!--   - `avgfacets`: average number of facets in the lower bound set (i.e. in $\mathcal{L} + \mathbb{R}^p$). -->
<!--   - `avgNDf`: average number of strictly non-dominated facets. -->
<!--   - `pctavgNDf`: proportion (in %) of facets that are strictly non-dominated. -->
<!--   - `avgWNDf`: average number of weekly non-dominated facets. -->
<!--   - `pctavgWNDf`: proportion (in %) of facets that are weekly non-dominated. -->
<!--   - `maxfacets`: maximal number of facets a lower bound set had in the tree. -->
<!--   - `maxNDf`: number of strictly non-dominated facets in the lower bound set with the maximal number of facets. -->
<!--   - `pctmaxNDf`: proportion (in %) of facets that are strictly non-dominated in the lower bound set with the maximal number of facets. -->
<!--   - `maxWNDf`: number of weekly non-dominated facets in the lower bound set with the maximal number of facets. -->
<!--   - `pctmaxWNDf`: proportion (in %) of facets that are weekly non-dominated in the lower bound set with the maximal number of facets. -->
<!--   - `tpstotal`: CPU time (in sec) used to solve the instance. 3600 if the instance is not solved. -->
<!--   - `tpsLB`: CPU time (in sec) used to compute lower bound sets. -->
<!--   - `pcttpsLB`: proportion (in %) of the total CPU time spend in the computation of lower bound sets. -->
<!--   - `tpsdomi`: CPU time (in sec) used to dominance test when the algorithm has to determine whether a node can be pruned by dominance or not. -->
<!--   - `pcttpsdomi`: proportion (in %) of the total CPU time spend in the dominance test when the algorithm has to determine whether a node can be pruned by dominance or not. -->
<!--   - `tpsUB`: CPU time (in sec) used to update the upper bound set. -->
<!--   - `pcttpsUB`: proportion (in %) of the total CPU time spend in updating the upper bound set. -->
<!--   - `tpsnodesel`: CPU time (in sec) used to choose the next node to develop. -->
<!--   - `pcttpsnodesel`: proportion (in %) of the total CPU time spend in choosing the next node to develop. -->
<!--   - `tpsvarsel`: CPU time (in sec) used to choose the variable to branch on. -->
<!--   - `pcttpsvarsel`: proportion (in %) of the total CPU time spend in choosing the variable to branch on. -->
<!--   - `tpsOB`: CPU time (in sec) used to create the sub-problems in the objective space, i.e. to compute objective branching. (/!\ it requires two different steps in total: computing the SLUBs but also do additional dominance test to determine the dominance status of each local upper bounds ! This number take into account the two steps.) -->
<!--   - `pcttpsOB`: proportion (in %) of the total CPU time spend in computing objective branching. -->
<!--   - `tpsSLUB`: CPU time (in sec) used to compute the super local upper bounds. -->
<!--   - `pcttpsSLUB`: proportion (in %) of the total CPU time spend in computing the super local upper bounds. -->
<!--   - `tpsdomiLUB`: CPU time (in sec) used to do the additional dominance tests to get the dominance status of EACH local upper bound. -->
<!--   - `pcttpsdomiLUB`: proportion (in %) of the total CPU time spend in doing the additional dominance tests on the local upper bounds. -->
<!--   - `nbOB`: number of nodes where two or more sub-problems are created in the objective space. When using the exact objective branching (`OB` = exact), it in particular shows how often it is actually possible to split the objective space with the definition of the sub-problems that we used ($z(x) \leqq \bar{z}$, $\bar{z} \in \mathbb{R}^p$). -->
<!--   - `pctnbOB`: proportion (in %) of the nodes explored that where split in two or more sub-problems in the objective space. -->
<!--   - `avgdepthOB`: [relevant only if `OB` = exact] average depth of the nodes split in two or more sub-problems in the objective space. -->
<!--   - `mindepthOB`: [relevant only if `OB` = exact] minimal depth of the nodes split in two or more sub-problems in the objective space. -->
<!--   - `maxdepthOB`: [relevant only if `OB` = exact] maximal depth of the nodes split in two or more sub-problems in the objective space. -->
<!--   - `avgnbpbOB`: [relevant only if `OB` = exact] average number of sub-problems created in the objective space in the nodes split in two or more sub-problems in the objective space. -->
<!--   - `maxnbpbOB`: [relevant only if `OB` = exact] average number of sub-problems created in the objective space in the nodes split in two or more sub-problems in the objective space. -->

<!-- For each instance we also store the non-dominated set $\mathcal{Y}_N$ found by the algorithm and if an exact solution was found the efficient set $\mathcal{X}_E$. Statistics of how the nondominated points are found are stored in `yNStat`. The statistics are the following: -->

<!--   - the $p$ first columns correspond the values of the objective functions. -->
<!--   - `node`: number of the node where this point has been discovered. The higher this number is, the later the point has been discovered. -->
<!--   - `time`: time (in sec) elapsed between the start of the algorithm and when this point has been found (for the first time). -->
<!--   - `depth`: depth of the node where this point has been found (for the first time). -->

<!-- `yNStat` are sorted in exactly the same order as $\mathcal{X}_E$, i.e. each row represent the non-dominated point and its corresponding solution. -->


# Performance of the different algorithm configurations

```{r}
tmp <- datAllJoined %>% 
  group_by(algConfig) %>% 
  summarize(cpu = mean(tpstotal)) %>% 
  mutate(pct = cpu/min(cpu), strV = str_c(algConfig, " (", round((pct-1) * 100), "%)")) %>% 
  arrange(cpu) 
winSq <- tmp %>% pull(algConfig)
tmp <- tmp %>% pull(strV)
# datAll %>% group_by(algConfig) %>% summarize(cpu = mean(tpstotal)) %>% arrange(cpu) %>% kable()
# datAll %>% group_by(algConfig, pb) %>% summarize(cpu = mean(tpstotal)) %>% arrange(pb, cpu) %>% kable()
```

First, we rank the configurations with respect to mean cpu time for all instances, the sequence from best to worst becomes `r tmp` where the increase in percent compared to the best configuration is given in parentheses. Note that the mean cpu times calculated is in fact a lower bound due to the total run time limit. 

Second, a comparison of the different algorithm configurations given problem class can be seen in Figure \@ref(fig:perfPlotPct). Remark that we have increased the variable size for each problem class until the size becomes so big that some instances cannot be solved within the time limit. That is, the number of instances solved before the time limit are under 100%.   

```{r}
tmp <- datAll %>%
  group_by(algConfig, pb) %>%
  arrange(tpstotal) %>%
  mutate(count = row_number(), total = n()) %>% 
  group_by(pb) %>% 
  mutate(total = max(total)) %>% 
  group_by(pb, algConfig, tpstotal) %>% 
  arrange(pb, algConfig, tpstotal, count) %>% 
  filter(tpstotal < 1800 | row_number() == 1) %>% 
  mutate(pct = count/total) %>% 
  select(pb, algConfig, tpstotal, count, pct, total, OB, nodeselVarsel)
```


```{r perfPlot, eval=FALSE, fig.asp=1.2, fig.cap="Performance profile: Number of instances in percent solved given cpu time. An instance is considered as unsolved if the cpu time exceeds 1800 seconds (time limit)."}
ggplot(tmp) +
  geom_step(aes(x=tpstotal, y=count, color = OB, linetype = nodeselVarsel)) +
  facet_grid(rows = vars(pb), scales = "free") +
  ggtitle(str_c("Number of instances solved within a given cpu time")) +
  labs(color = "nS:", linetype = "oB:") +
  scale_color_ob + scale_linetype_nodesel_varsel +
  theme(legend.position="bottom") + xlab("cpu") + ylab("count")
```

```{r perfPlotPct, fig.asp=1.2, fig.cap="Performance profile: Number of instances in percent solved given cpu time. An instance is considered as unsolved if the cpu time exceed 1800 seconds (time limit)."}
ggplot(tmp) +
  # geom_step(aes(x=tpstotal, y=count, color = nodeselVarsel, linetype = OB)) +
  geom_step(aes(y=pct, x=tpstotal, color = OB, linetype = nodeselVarsel), alpha = 0.75) +
  # geom_point(aes(y=..y.., x=tpstotal, color = OB, linetype = nodeselVarsel), stat="ecdf", size = 1) +
  facet_grid(rows = vars(pb)) +
  ggtitle(str_c("Number of instances solved within a given cpu time")) +
  labs(color = "nS:", linetype = "oB:") +
  scale_color_ob + scale_linetype_nodesel_varsel +
  theme(legend.position="bottom") + xlab("cpu (seconds)") + ylab("%") + 
  coord_cartesian(expand = FALSE, ylim = c(0, NA), xlim = c(-10, 1797)) 
```

Some observations based on Figure \@ref(fig:perfPlotPct) are:

* In general exact objective branching (`B|E` and `D|E`) performs poorly compared to the other configurations. This is especially evident for AP and UFLP. For KP exact objective branching are still among the worst ones. 

* For both KP and UFLP, the best objective branching configuration is using a single cone (`C`), while no objective branching (`N`) performs better for AP. 

* In general breadth first strategies tend to perform better than depth first strategies. 

These observations will be explored with more details in the next sections.

<!--Thus, the `B|E` and `D|E` will be discarded in the rest of this paper. [say that we discard it in the enxt section, after explanations]-->




<!-- How can the performance of the objective branching be explained? -->
# Objective branching: a closer look

For taking a closer look at the different objective branching configurations we limit us to the set of instances which have been solved to optimality for all algorithm configurations. Detailed summary statistics are given in Table \@ref(tab:resTable). 

```{r resTable, layout="l-screen-inset"}
dat <- datAll %>% 
  group_by(instance) %>%
  filter(n() == algConfigsN, min(solved) == 1) %>%
  ungroup() 
winSeq <- unique(dat$algConfig)
getResGroup <- function(dat, ...) {
  # winSeq <- dat %>% 
  #   group_by(algConfig) %>% 
  #   summarize(cpu = mean(tpstotal)) %>% 
  #   mutate(pct = cpu/min(cpu), strV = str_c(algConfig, " (", round((pct-1) * 100), "%)")) %>% 
  #   arrange(cpu) %>% pull(algConfig)
  cols = c("cpu", "cpuLB", "nodes", "prune")  # columns for each group
  colN <- purrr::flatten_chr(map(cols, function(x) str_c(x, winSeq, sep = "_")))
  idx <- {
    lgd <- length(winSeq)
    idx <- NULL
    for (i in 1:length(winSeq))
      for (j in 1:length(cols))
        idx <- c(idx, i + (j-1)*lgd)
    idx
  }
  colN <- colN[idx]
  
  datYN <- dat %>% 
    group_by(instance, ...) %>% 
    summarise(YN = max(YN), YNse = max(YNse), YNs = max(YNs)) %>% 
    group_by(...) %>% 
    summarise(YN = mean(YN), YNse = mean(YNse), YNs = mean(YNs)) 

  datResults <- dat %>% 
    group_by(..., algConfig) %>% 
    summarise(ct = n(), cpu = mean(tpstotal), cpuMax = max(tpstotal), cpuMin = min(tpstotal), 
              nodes = mean(nbnodes), nInf = mean(pctinfeas), nOpt = mean(pctopt), nDom = mean(pctdomi),
              dptLeaf = mean(avgdepthT), dptMinLeaf = mean(mindepthT), dptMaxLeaf = mean(maxdepthT),
              solved = min(solved), cpuLB = 1000*mean(tpsLB/nbLB)) %>% 
    full_join(datYN) %>% 
    mutate(cpu = if_else(cpu == min(cpu), str_c(round(cpu, 1), "!"), str_c(round(cpu, 1))),
           cpuLB = if_else(cpuLB == min(cpuLB), str_c(round(cpuLB, 1), "!"), str_c(round(cpuLB, 1))),
           nodes = if_else(nodes == min(nodes), str_c(round(nodes, 0), "!"), str_c(round(nodes, 0)))) %>% 
    ungroup() %>% 
    mutate(cpu = if_else(solved == 1, 
                         str_c(cpu, " [", round(cpuMin,1), ",", round(cpuMax,1), "]"), 
                         str_c(cpu, "*", " [", round(cpuMin,1), ",", round(cpuMax,1), "]")),
           YN = str_c(round(YN), " (", round(100*YNse/YN), "/", round(100*(YNs-YNse)/YN), "/", round(100*(YN-YNs)/YN), ")"),
           nodes = str_c(nodes, " [", round(dptMinLeaf), ",", round(dptLeaf), ",", round(dptMaxLeaf), "]"),
           prune = str_c("[", round(nInf), ",", round(nOpt), ",", round(nDom), "]")
           ) %>%
    select(-solved, -cpuMin, -cpuMax, -dptMinLeaf, -dptMaxLeaf, -dptLeaf, -nInf, -nOpt, -nDom) %>%
    pivot_wider(names_from = c(algConfig), values_from = c(cpu, cpuLB, nodes, prune)) %>%
    select(..., ct, YN, !!colN)
  return(datResults)
}
datResRows <- getResGroup(dat, pb, n)
tabResults <- NULL
for (p in unique(datResRows$pb)) {
  dat1 <- datResRows %>% filter(pb == p)
  dat2 <- getResGroup(dat, pb) %>% filter(pb == p)
  tabResults  <- bind_rows(tabResults, dat1, dat2)
}

colsN = c("cpu", "cpuLB", "nodes", "prune")
tabResults <- tabResults %>% 
  mutate_at(vars(contains(c("cpu", "cpuLB", "nodes"))), ~cell_spec(., bold = if_else(str_detect(., fixed("!")), T, F))) %>% 
  mutate_if(is.character, str_replace_all, pattern = "!", replacement = "")
# digits <- c(0,0,0,rep(c(1,0,0),algConfigsN))
tabResults %>% 
  select(-pb) %>% 
  kable(
    # digits = digits, 
    escape = F,
    col.names = c(str_c("n", footnote_marker_alphabet(1)), 
                  str_c("#", footnote_marker_alphabet(2)), 
                  str_c("|YN|", footnote_marker_alphabet(3)),  
                  str_c(rep(colsN, length(winSeq)),  
                        c(footnote_marker_alphabet(4),
                          footnote_marker_alphabet(5),
                          footnote_marker_alphabet(6),
                          footnote_marker_alphabet(7)))
    ),
    caption = "Detailed results for all instances which have been solved to optimality for all algorithm configurtions.") %>% 
  add_footnote(label = c("Number of variables.", 
                         "Number of instances.", 
                         "Avg. number of non-dominated points (supported extreme, supported non-extreme and unsupported in percent).",
                         "Avg. cpu time (seconds). Square brackets contains the range.",
                         "Avg. cpu time (miliseconds) used to find the LB set per node where LB set found.",
                         "Avg. number of nodes in the branching tree. Square brackets contains the min, avg. and max depth of leaf nodes.",
                         "Percentages of leaf nodes pruned by infisibility, optimality and dominance."
                         )
               ) %>% 
  kable_styling() %>% 
  add_header_above(c(" " = 3, setNames(rep(length(colsN), length(winSeq)), winSeq))) %>% 
  pack_rows("AP", min(which(tabResults$pb == "AP")), max(which(tabResults$pb == "AP"))) %>% 
  pack_rows("KP", min(which(tabResults$pb == "KP")), max(which(tabResults$pb == "KP"))) %>% 
  pack_rows("UFLP", min(which(tabResults$pb == "UFLP")), max(which(tabResults$pb == "UFLP"))) %>% 
  row_spec(c(max(which(tabResults$pb == "AP")), 
             max(which(tabResults$pb == "KP")), 
             max(which(tabResults$pb == "UFLP"))), italic = T, background = "lightgrey") %>% 
  scroll_box(width = "100%")
```

Figure \@ref(fig:perfPlotPct) illustrates that using exact objective branching (`E`) is not efficient with respect to cpu time. As explained in Section 4.3, exact objective branching may create several sub-problems in the objective space resulting in more nodes in the branch and bound tree. This may lead to higher computational times if the algorithm cannot explore them all fast enough. Indeed, this can be seen in Figure \@ref(fig:figTreeSize) where `E` configurations produce more nodes in the tree compared to `C` and `N` given same node selection rule. This observation makes sense, as the purpose of objective branching as described in Algorithm 2 is to produce more sub-problems and thus get wider trees with a smaller depth. 

```{r figTreeSize, fig.cap="Average branching tree size."}
datAll %>% 
  group_by(instance) %>%
  filter(n() == algConfigsN, min(solved) == 1) %>%
  ungroup() %>% 
  group_by(pb, OB, nodeselVarsel) %>% 
  summarise(node = mean(nbnodes)) %>% 
  group_by(pb) %>% 
  arrange(node) %>% 
  ggplot(aes(x = pb, y = node, fill = OB, linetype = nodeselVarsel)) + 
  geom_col(position = "dodge2", color = "black") +
  # geom_line(alpha = 0.75) +
  # geom_point(alpha = 0.75) +
  facet_grid(cols = vars(pb), scales = "free") + 
  # ggtitle(str_c("Average branching tree size.")) +
  labs(color = "oB:", linetype = "nS:") +
  scale_fill_ob + scale_linetype_nodesel_varsel +
  theme(legend.position="bottom") + xlab("problem class") + ylab("tree size") 
```



```{r}
tmp <- datAll %>% 
  group_by(instance) %>%
  filter(n() == algConfigsN) %>%
  ungroup()  %>% 
  filter(OB == "E") %>% 
  # group_by(pb) %>% 
  summarise(avgnbpbOB = mean(avgnbpbOB)) %>% pull(avgnbpbOB)
```

<!-- In practice, as it can be seen in Table \@ref(tab:resTable), in general, `E` configurations indeed produce more nodes in the tree than the other configurations.  -->

Furthermore, under exact objective branching the lower bound sets are harder to calculate [LRN: we need to add a statistic cpu/LP solved]. This indicates that the sub-problems generated in the `E` configurations tends to be harder to solve due to a more complicated set of constraints. 

<!-- This observation makes sense, as the purpose of objective branching as described in Algorithm 2 is to produce more sub-problems (and thus get wider trees), hoping that the tree will go less deep by making more local decision. When we look at the average depth of the tree in \@ref(tab:resTable), it can be seen that it is generally lower for `E` than for `C`. Thus, it means that the nodes in `E` configurations are closer to the root node and thus, the corresponding sub-problems may be more complex. Indeed, the more a node is deep in the tree, the less complex the lower bound set tends to be (up to a single point at depth $n + 1$). This phenomenon may be minimized by introducing for example an updating procedure of the lower bound set, instead of a computation from scratch at each node as it is done currently in our implementation. Hence, the complexity of computing the lower bound set, no matter how deep it is in the tree, would be approximately the same. -->



<!-- As most of the computational time is spent in computing the lower bound sets in our branch and bound algorithm (approx. [LRN: add average percentage]), the last observation may  -->
<!-- For example, Table \@ref(tab:resTable) shows that for Knapsack problems for `n` = 30, the number of nodes for the configurations `D|C` and `D|E` is approximately the same (between 180000 and 190000). However, the first configuration is about 3 times faster than the second one. -->

<!-- A possible explanation is that the linear relaxation of the problems studied is of good quality in the single-objective case [ref ?]. Thus, integer extreme points can be found very early (i.e. at a very low depth) in the branch and bound tree. For example, all the extreme points of the linear relaxation of an AP are integer and are thus new candidates for being part of the final non-dominated set. Hence, while using depth first strategies, the branch and bound algorithm tends to focus to specific parts of the objective space one by one; using breadth first strategies offer a better coverage of all the objective space earlier and thus, yields better upper bound sets earlier. -->



Another way to improve and possibly make `E` competitive would be to make more use of the local information provided by the sub-problems in the objective space. For example, as presented in [I have to find ref again, it's somewhere in my references list], pre-processing in the multi-objective case has much less impact than in the single-objective case, as the efficient solutions may differ a lot. However, one could imagine that the solutions are more likely to be close in a specific part of the objective space and thus, by localising the branch and bound, pre-processing or introducing cuts may have a significantly more impact.

Except for AP, the `C` configurations are performing better than the `N` configurations. A first explanation of the efficiency of `C` for KP and UFLP is that for a given node $\eta$, the `C` configurations will focus on a specific part of the objective space (a cone defined by $d^N(\eta)$). Thus, the lower bound sets tends to be less complex (some areas of the objective space are discarded before computation, while it is fully considered in the `N` version), which means possibly spending less time in the most expensive part of the branch and bound (computing the lower bound sets).

In addition to that, the way nodes are fathomed is highly influenced. Indeed, as it can be seen in Table \@ref(tab:resTable), in the `C` configurations, the proportion of nodes fathomed by infeasibility tends to be much higher than for the `N` configurations.  Besides, fathoming a node by infeasibility is faster than fathoming a node by optimality or by dominance. Indeed, to fathom by dominance or optimality, having the lower bound set computed is required. On the contrary, testing the feasibility of the sub-problem is the first thing done when a node is being explored and thus, a node fathomed by infeasibility is explored faster (see [report] for how much faster it is in practice).
<!-- It comes from the fact that additional constraints are added in the `C` configurations, making sub-problems more likely to be infeasible (and this phenomenon can be observed as well for `E`). -->

The case of AP is a special. Indeed, in the `N` version, as the single-objective AP is in P, all the extreme points of the lower bound sets will always be integer. Thus, when a variable is chosen for branching, the special branching rule is triggered: the one chosen is the variable that is the most often different. However, in the `C` configurations, due to the fact that new constraints are added, the extreme points may have fractional values and thus, the branching rule differs from `N` configurations. It seems to have a significant impact on the branch and bound tree, which make the `N` configurations be the best.

In conclusion, it seems that how objective branching behave and whether it is efficient or not is very sensitive to the choices made in the other components of the branch and bound tree (variable selection, lower bound set, pre-processing...). The reader is refered to [report] to see more about that.

<!-- [LRN: Plot for winning configurations -> `n` as x-axis and percentages of instances as y-axis. Have a color for the 6 configurations + another one for unsolved instances for all the configurations. Do a "stack plot", in the spirit of the plot called "Pct for each configuration given 10 bins" in Research question 3 from the old report] -->
<!-- [extra observation: with such a plot, we will be able to see that the number of unsolved instances grows with the size of the instance as well] -->

<!-- [NF: a few words about winning configurations] -->

<!-- [LRN: put a star for n if some instances are unsolved for all configurations. For ex KP 35 -> 21 config with at least 1 config solved -> put 30* instead] -->

<!-- [LRN: prune column as stack plot. One color for infeasibility, optimality and dominance. `n` as x-axis, percentages as y-axis.] -->

<!-- [LRN: number of nodes as a plot. One line for each configuration, `n` as x-axis, number of nodes as y-axis.] -->

<!-- [LRN: average depth as a plot. One line for each configuration, `n` as x-axis, average depth as y-axis. You may drop the `N` configurations for OB here, as they are not used.] -->


# Node selection: breadth vs depth

<!-- # How well does the tri-objective B&B algorithm perform compared to an objective space search algorithm? -->
# Comparing the branch and bound algorithm with an objective space search algorithm

The best configuration of our branch and bound framework will now be compared to an efficient objective space search algorithm from the litterature [ref PhD Tamby]. Note that the goal of this paper is more like reaching a new step in making the branch and bound efficient in the multi-objective case by extending a concept that made branch and bounds more efficient in the bi-objective case, than to design an algorithm that performs better than objective space search algorithms on a specific set of instances. However, as the goal for futur research is to obtain a competitive branch and bound algorithm in the multi-objective case, we still want to compare to an objective space search algorithm, to see how far this goal is.

The principle of the algorithm from [ref Tamby] is to explore sub-problems that are defined by the current set of local upper bounds, that itself evolve when new non-dominated points are found. Using this approach, the authors expose a way to warmstart the MIP solver for each sub-problem expored as well as rules that discard sub-problems without even solving them, which both greatly improve the computational time. They show in their experiments that their algorithm performs better than some of the classical objective space search algorithm from the litterature.

As the LP solver in Bensolve is GLPK, the MIP solver that we will use for this algorithm is GLPK as well. Due to a technical constraint in the chosen programming language (Julia), the MIP solver could not be warmstarted. Hence, one should keep in mind that the cpu times for the objective space search algorithm are upper bounds on their actual cpu time.

[LRN: performance profile -> best config B&B vs Objective Space Search (OSS) algorithm. See stat_OSS.csv, columns "solved" (1 if instance solved, 0 otherwise) and "cpu" (cpu time expressed in seconds) for OSS algorithm. One performance profile per problem class ?]

[NF: a few words about the results]


<!-- # Variable selection strategy -->

<!-- Average results based on different groupings: -->

<!-- ```{r} -->
<!-- datObNC %>% group_by(varsel) %>% summarise(cpu = mean(tpstotal), nodes = mean(nbnodes)) %>% arrange(cpu) %>% kable() -->
<!-- datObNC %>% group_by(varsel, pb) %>% summarise(cpu = mean(tpstotal), nodes = mean(nbnodes)) %>% arrange(pb, cpu) %>% kable() -->
<!-- datObNC %>% group_by(nodesel, varsel, pb) %>% summarise(cpu = mean(tpstotal), nodes = mean(nbnodes)) %>% arrange(nodesel, pb, cpu) %>% kable() -->
<!-- ``` -->


<!--
# ToDo

Based on the above:

- We suggest to only consider spheredown results (the ones reported in this report).
- Generate harder instances until hit the time limit of 30 min. 
- Should we generate multi-dim KP also?
- Research questions and sequence?

[OLD STUFF to be removed.]
-->

<!--
# Numerical instabilities
-->

<!-- In order to compute the linear relaxation at each node, the solver [Bensolve](https://www.optimierung-loehne.uni-jena.de/bensolve) is used. To avoid parsing a lot a files at each node in our implementation, a wrapper that calls bensolve, retrieve some outputs and introduce them directly in our code as matrices, has been made. -->

<!-- The retrieved outputs are the extreme rays, the extreme points (in the objective space), their pre-image (in the decision space) and a list of extreme points and rays that constitute each facet of the lower bound set. -->

<!-- To proceed the dominance test in the branch and bound, the normal vector of each facet of the lower bound set is required. At this point, as only a description using extreme points is available, the normal vectors will be computed using linear algebra. From the extreme points and extreme rays of a facet $f$ given by Bensolve, it is always possible to determine $p$ linearly independant points $x^1,...,x^p$ of this facet. To obtain the normal vector of $f$, the system $M \cdot n^f = 0$ is solved, where $n^f$ is the normal vector of $f$ and $M$ is a matrix such that each row $M_i = x^1 - x^p$, $\forall i \in \{1,...,p-1\}$ and $M_p = (1,...,1)$. -->

<!-- However, this system is sometimes close to be singular, leading to numerical instabilities in the components of the normal vectors. This imply that occasionally, a facet may be slightly not correctly oriented, which may be a problem in the dominance test (e.g. considering a local upper bound as non-dominated while it is dominated, and the other way around). -->

<!-- Two equivalent epsilons can be introduced here in order to overcome these numerical instabilities. First, the facet such that the determinant of their matrix $M$ is too close to 0 are discarded. In other words, if $det(M) \leq \epsilon$, the facet is deleted. The other possibility is to move down the whole lower bound set by reducing from an epsilon the right-hand side of the equations of the facets, i.e. the equation of each facet $f \in \mathcal{L}(\eta)$ becomes $n^fy = d - \epsilon$ instead of $n^fy = d$. Both method produce weaker lower bound set, leading to greater computational times, but reducing the chances of missing a non-dominated point due to numerical instabilities. -->

<!-- Very rarely, GLPK, the single-objective LP solver used by Bensolve, rises a warning for numerical instabilities as well. Unfortunately, there is no way for us to avoid these, but fortunately, these cases occur much less often. -->

<!-- The list of instances where a different number of non-dominated points in some of the configurations has been found due to numerical instabilities can be found below: -->

<!--
Currently we have instabilities with instances: `r datNotStable$instance`.
-->



  



<!-- The primary focus is on computational time and number of nodes explored the size of the branching -->
<!-- tree before the algorithm ends. -->

<!-- The second purpose of this study is to learn how the characteristics of an instance can affect its -->
<!-- difficulty. The difficulty will be here measured by the *size of the non-dominated set*, and the -->
<!-- *computational time* required to solve the instance. The computational time will be determined -->
<!-- using the branch and bound algorithm previously described. Note that the complexity of an objective -->
<!-- space search algorithm is positively correlated to the size of the non-dominated set as the more -->
<!-- non-dominated there are, the more integer programs have to be solved. -->







 


<!-- # Analysis: Research Question 1 (R1) - How do input statistics affect the number of nondominated solutions? -->

<!-- In this section, relations between |YN| (`YN`) and various input statistics. How do input -->
<!-- statistics affect the number of nondominated solutions? -->

<!-- ## R1a: Does the cost range have an effect? -->

<!-- Note that the number of nondominated points increase with the number of variables which is due to the total possible range of the objectives increase with `n` (there is room for more points).  -->

<!-- ```{r} -->
<!-- plot_ly(x = ~rangeGapZ1, y = ~rangeGapZ2, z = ~rangeGapZ3, type="scatter3d", -->
<!--         mode="markers", -->
<!--         data = datAll %>% dplyr::filter(pb == "AP"), -->
<!--         marker = list(size=3), -->
<!--         color = ~n) %>% plotly::layout(title = "AP") -->
<!-- plot_ly(x = ~rangeGapZ1, y = ~rangeGapZ2, z = ~rangeGapZ3, type="scatter3d", -->
<!--         mode="markers", -->
<!--         data = datAll %>% dplyr::filter(pb == "KP"), -->
<!--         marker = list(size=3), -->
<!--         color = ~n) %>% plotly::layout(title = "KP") -->
<!-- plot_ly(x = ~rangeGapZ1, y = ~rangeGapZ2, z = ~rangeGapZ3, type="scatter3d", -->
<!--         mode="markers", -->
<!--         data = datAll %>% dplyr::filter(pb == "UFLP"), -->
<!--         marker = list(size=3), -->
<!--         color = ~n) %>% plotly::layout(title = "UFLP") -->
<!-- ``` -->



<!-- ## R1b: Does the generation method of the objective coefficients (`coef`) have an effect? -->

<!-- ```{r, fig.asp = 1} -->
<!-- datP <- datAll %>%   -->
<!--   dplyr::filter(solved==1) %>%  -->
<!--   select(instance, pb, n, p, coef, rangeC, ratioNDcoef, YN) %>%  -->
<!--   distinct()  -->

<!-- ggplot(datP, aes(y = YN , x = n)) + -->
<!--   geom_jitter(aes(color = coef)) + -->
<!--   facet_grid(cols = vars(pb), margins = T) + -->
<!--   ggtitle("Effect of generation method (|YN| for each instance)") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) -->

<!-- datPA <- datP %>% -->
<!--   group_by(pb, coef, rangeC, n) %>% -->
<!--   dplyr::summarise(YN = mean(YN)) -->
<!-- ggplot(datPA, aes(y = YN , x = n)) + -->
<!--   geom_jitter(aes(color = coef)) + -->
<!--   facet_grid(cols = vars(pb), margins = T, scales = "free") + -->
<!--   ggtitle("Effect of generation method (average |YN| for each instance group)") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- ``` -->

<!-- Based on the plots we may answer the research question by concluding that the objective coefficient generation method have a high effect on the number of solutions. Random generation on average produce the lowest amount, then 2box. The two sphere methods seems to give approx. the same results.  -->

<!-- Note in general the speed of the algorithm is highly correlated with the number of non-dominated points. That is, instances with a high number of nondominated points are harder to solve. Based on this we may conclude that using one of the sphere methods for further study seems a good choice. We may also consider comparing it against the easiest method.   -->




<!-- # Analysis: Research Question 2 (R2) - Which instances are hard to solve? -->

<!-- We focus on cpu time (`tpstotal`) and try to get an overview over difficulty of the instances. -->

<!-- ## R2a: What is the cpu for each instance? -->

<!-- First let us have a general look of the performance: -->



<!-- <!-- The general picture is fuzzy due to different problem classes, ranges, generation methods and algorithm configurations. --> -->

<!-- Let us have a look for different problem classes, ranges, generation methods and algorithm configurations: -->



<!-- Finally we may plot only the winner cpu times for each instance: -->

<!-- ```{r, fig.asp=1} -->
<!-- datP <-  -->
<!--   datAll %>%  -->
<!--   group_by(instance) %>%  -->
<!--   nest() %>%  -->
<!--   mutate(data = map(data, function(df) {df %>% arrange(tpstotal) %>% slice(1)})) %>%  -->
<!--   mutate(win = map(data, function(df) {str_c(df$nodesel[1], ".", df$varsel[1], ".", df$OB[1])})) %>%  -->
<!--   unnest(c(win, data))  -->

<!-- plotCPUWinner <- function() { -->
<!--   datPP <- datP  -->
<!--   plt <- ggplot(datPP, aes(y = tpstotal , x = n)) +  -->
<!--     # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--     geom_jitter(aes(color = win), width = 3, height = 0, size = 0.7) + -->
<!--     facet_grid(cols = vars(pb), scales = "fixed") + -->
<!--     ggtitle(str_c("Cpu time")) + -->
<!--     theme(legend.position="bottom", legend.title=element_blank()) + -->
<!--     coord_cartesian(ylim = c(0, 100)) -->
<!--   print(plt) -->
<!-- } -->
<!-- plotCPUWinner() -->
<!-- ``` -->

<!-- Some observations -->

<!--   - There is no clear winner among the different algorithm configurations. -->
<!--   - There seems to be a bigger difference for KP. -->
<!--   - Hardest instances are the one generated with the sphere methods. -->

<!-- ## R2b: Which sphere generation instances are hardest to solve? -->

<!-- Let us consider ranges [1,1000] and [1,1000][1,100]: -->

<!-- ```{r, fig.asp=1} -->
<!-- res <- datP %>%  -->
<!--   dplyr::filter(grepl("sphere", coef) & grepl("1,1000", rangeC) & !grepl("1001,2000", rangeC)) %>%  -->
<!--   group_by(pb, coef) %>%  -->
<!--   summarize_at(vars(contains("YN") | tpstotal), mean)  -->
<!-- res -->
<!-- # ggplot(res, aes(y = avgCpu , x = n)) +  -->
<!-- #   geom_jitter(aes(color = coef), width = 3, height = 0, size = 0.7) + -->
<!-- #   facet_grid(rows = vars(interaction(nodesel,varsel,OB)), cols = vars(pb), margins = T, scales = "free") -->
<!-- #    -->
<!-- #    -->
<!-- #     geom_jitter(aes(color = interaction(nodesel,varsel,OB)), width = 3, height = 0, size = 0.7)  -->
<!-- # + -->
<!-- #     facet_grid(rows = vars(coef), cols = vars(rangeC), margins = T, scales = "free") + -->
<!-- #     ggtitle(str_c("Cpu time for ", pb, " (note scale free)")) + -->
<!-- #     theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- #  -->
<!-- # res <- datP %>%  -->
<!-- #   dplyr::filter(grepl("sphere", coef), grepl("[1,1000]", rangeC)) %>%  -->
<!-- #   group_by(pb, coef) %>%  -->
<!-- #   summarize(avgCpu = mean(tpstotal)) %>%  -->
<!-- #   arrange(pb, desc(avgCpu)) -->
<!-- # res -->

<!-- # ggplot(res, aes(y = pct, x = win, fill = win)) +  -->
<!-- #   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!-- #   geom_col() +  -->
<!-- #   facet_grid(rows = vars(pb), cols = vars(coef), scales = "fixed") + -->
<!-- #   ggtitle("Winner pct") + -->
<!-- #   theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- #  -->
<!-- #  -->
<!-- # ggplot(datPP, aes(y = tpstotal , x = n)) +  -->
<!-- #   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!-- #   geom_jitter(aes(color = win), width = 4, height = 0, size = 0.7) + -->
<!-- #   facet_grid(rows = vars(coef), cols = vars(rangeC), scales = "fixed") + -->
<!-- #   ggtitle("Cpu time for UFLP") + -->
<!-- #   theme(legend.position="bottom", legend.title=element_blank())  -->
<!-- ``` -->

<!-- There is no clear winner. Moreover, the shape of the nondominated set is not affected much by the generation method. -->

<!-- ## R2c: Is the cpu time the same within each instance group? -->

<!-- By instance group we mean an unique combination of `namePrefix`, `constId`, `pb`, `n`, `coef`, `rangeC`, `nodesel`, `varsel`, `OB` -->

<!-- ```{r} -->
<!-- # datP <- datAll %>%  -->
<!-- #   select(instance, namePrefix, insId, constId, pb, n, coef, rangeC, ratioNDcoef, nodesel, varsel, OB, YN, tpstotal) %>% #contains("tps") -->
<!-- #   mutate(iG = str_c(namePrefix, constId, pb, n, coef, rangeC, nodesel, varsel, OB, sep = ".")) -->
<!-- datP <- datAll %>%  -->
<!--   select(instance, namePrefix, insId, constId, pb, n, coef, rangeC, ratioNDcoef, nodesel, varsel, OB, YN, tpstotal) %>% #contains("tps") -->
<!--   group_by(namePrefix, constId, pb, n, coef, rangeC, nodesel, varsel, OB) %>% nest() -->

<!-- datPSd <- datP %>%  -->
<!--   mutate( -->
<!--     stdDevV = map(data, function(df) { -->
<!--       df %>% summarise_if(is.numeric, sd) -->
<!--     }), -->
<!--     # meanV = map(data, function(df) { -->
<!--     #   df %>% summarise_if(is.numeric, mean) -->
<!--     # }), -->
<!--     cvV = map(data, function(df) { -->
<!--       df %>% summarise_if(is.numeric, function(x) {sd(x)/mean(x)}) -->
<!--     }), -->
<!--     maxV = map(data, function(df) { -->
<!--       df %>% summarise_if(is.numeric, max) -->
<!--     }) -->
<!--   ) %>% unnest(c(stdDevV, cvV, maxV), names_sep = "_") -->

<!-- # ggplot(datPSd, aes(y = meanV_tpstotal, x = n)) +  -->
<!-- #   geom_jitter(aes(color = rangeC, shape = interaction(nodesel, varsel, OB))) +  -->
<!-- #   facet_grid(rows = vars(coef), cols = vars(pb), margins = T) + -->
<!-- #   ggtitle("Means") + -->
<!-- #   theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- ``` -->


<!-- ```{r, fig.asp=1} -->
<!-- ggplot(datPSd, aes(y = stdDevV_tpstotal, x = n)) +  -->
<!--   geom_jitter(aes(color = rangeC, shape = interaction(nodesel, varsel, OB))) +  -->
<!--   facet_grid(rows = vars(coef), cols = vars(pb), margins = T, scales = "free") + -->
<!--   ggtitle("Std. dev.") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- ``` -->


<!-- ```{r, fig.asp=1} -->
<!-- ggplot(datPSd, aes(y = cvV_tpstotal, x = n)) +  -->
<!--   geom_jitter(aes(color = rangeC, shape = interaction(nodesel, varsel, OB))) +  -->
<!--   facet_grid(rows = vars(coef), cols = vars(pb), margins = T, scales = "free") + -->
<!--   ggtitle("Coeff of variation (sd/mean)") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- ``` -->


<!-- ```{r, fig.asp=1} -->
<!-- ggplot(datPSd, aes(y = maxV_tpstotal, x = n)) +  -->
<!--   geom_jitter(aes(color = rangeC, shape = interaction(nodesel, varsel, OB))) +  -->
<!--   facet_grid(rows = vars(coef), cols = vars(pb), margins = T, scales = "free") + -->
<!--   ggtitle("Max values") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank())  -->
<!-- ``` -->

<!-- In general we may have high variation within instance groups. -->





<!-- ## R2d: In which subprocedures are the cpu time used? -->

<!-- ```{r} -->
<!-- res <- datAll %>% -->
<!--   select(instance, namePrefix, insId, constId, pb, n, coef, rangeC, ratioNDcoef, nodesel, varsel, OB, YN, contains("pcttps")) %>% -->
<!--   mutate(pcttpsmisc = 100 - (pcttpsLB + pcttpsdomi + pcttpsUB + pcttpsnodesel + pcttpsvarsel + pcttpsSLUB + pcttpsdomiLUB)) %>% -->
<!--   group_by(pb) %>% -->
<!--   nest() -->
<!-- res <- res %>%  -->
<!--   mutate( -->
<!--     meanV = map(data, function(df) { -->
<!--       df %>% summarise_if(is.numeric, mean) -->
<!--     }), -->
<!--   ) %>% unnest(c(meanV), names_sep = "_") -->
<!-- res <- res %>% pivot_longer(contains("pcttps")) -->
<!-- ggplot(res, aes(y = value, x = name, fill = name)) + -->
<!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--   geom_col() + -->
<!--   facet_grid(rows = vars(pb), scales = "fixed") + -->
<!--   ggtitle("Cpu usage") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- ``` -->


<!-- # Analysis: Research Question 3 (R3) - Which algorithm configuration is best? -->

<!-- ## R3a: Is there a clear winner? -->

<!-- Let us have a look at the problem classes: -->

<!-- ```{r} -->
<!-- datP <-  -->
<!--   datAll %>%  -->
<!--   group_by(instance) %>%  -->
<!--   nest() %>%  -->
<!--   mutate(data = map(data, function(df) {df %>% arrange(tpstotal) %>% slice(1)})) %>%  -->
<!--   mutate(win = map(data, function(df) {df$algConfig})) %>%  -->
<!--   unnest(c(win, data)) -->

<!-- res <- datP %>%  -->
<!--   group_by(pb) %>%  -->
<!--   mutate(count = n()) %>%  -->
<!--   group_by(pb, win) %>% summarize(pct = n()/mean(count)) %>%  -->
<!--   arrange(pb,desc(pct)) -->
<!-- ggplot(res, aes(y = pct, x = win, fill = win)) +  -->
<!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--   geom_col() +  -->
<!--   facet_grid(rows = vars(pb), scales = "fixed") + -->
<!--   ggtitle("Winner pct") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) +  -->
<!--   scale_fill_algConfig -->
<!-- ``` -->

<!-- Note if we look at different problem classes different variable selection methods may win. Do the generation method affect the winner: -->

<!-- ```{r} -->
<!-- res <- datP %>%  -->
<!--   group_by(pb, coef) %>%  -->
<!--   mutate(count = n()) %>%  -->
<!--   group_by(pb, coef, win) %>% summarize(pct = n()/mean(count)) %>%  -->
<!--   arrange(pb, coef, desc(pct)) -->
<!-- ggplot(res, aes(y = pct, x = win, fill = win)) +  -->
<!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--   geom_col() +  -->
<!--   facet_grid(rows = vars(pb), cols = vars(coef), scales = "fixed") + -->
<!--   ggtitle("Winner pct") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) +  -->
<!--   scale_fill_algConfig -->
<!-- ``` -->

<!-- If we group by `coef`, we have different winners. This may have something to do with the hardness of the instance (generation method is highly correlated with number of nondominated points).  -->

<!-- Will different methods be used for harder instances (here we use YN as a proxy for hard). Let us try to plot the aggregated percentage winner configuration: -->

<!-- ```{r} -->
<!-- res <- datP %>%  -->
<!--   group_by(pb, YN) %>%  -->
<!--   mutate(count = n()) %>%  -->
<!--   group_by(pb, YN, win) %>% summarize(pct = n()/mean(count)) %>%  -->
<!--   arrange(pb, YN, desc(pct)) -->
<!-- ggplot(res, aes(x = YN, fill = win)) +  -->
<!--   geom_histogram(position = "fill", bins = 10) +  -->
<!--   stat_bin(bins = 10, geom="text", colour="white", size=3.5, -->
<!--             aes(label=..count.., group = win), position=position_fill(vjust=0.5)) + -->
<!--   facet_grid(rows = vars(pb), margins = T, scales = "fixed") + -->
<!--   ggtitle("Pct for each configuration given 10 bins (numbers indicate instance counts)") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) +  -->
<!--   scale_fill_algConfig -->
<!-- ``` -->

<!-- It can be seen that for some problem classes the best configuration change from easy instances to hard. -->

<!-- ## R3b: Is the best node selection strategy affected by other algorithm configurations? -->

<!-- We consider all instances: -->

<!-- ```{r} -->
<!-- res <- datP %>%  -->
<!--   group_by(varsel, OB) %>%  -->
<!--   mutate(count = n(), win = nodesel) %>%  -->
<!--   group_by(varsel, OB, win) %>% summarize(pct = n()/mean(count)) %>%  -->
<!--   arrange(varsel, OB, desc(pct)) -->
<!-- ggplot(res, aes(y = pct, x = win, fill = win)) +  -->
<!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--   geom_col() +  -->
<!--   facet_grid(rows = vars(varsel), cols = vars(OB), scales = "fixed") + -->
<!--   ggtitle("Winner pct") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- ``` -->

<!-- ## R3c: Is the best variable selection strategy affected by other algorithm configurations? -->

<!-- We consider all instances: -->

<!-- ```{r, eval = FALSE} -->
<!-- res <- datAll %>% group -->

<!-- res <- datP %>%  -->
<!--   group_by(nodesel, OB) %>%  -->
<!--   mutate(count = n(), win = varsel) %>%  -->
<!--   group_by(nodesel, OB, win) %>% summarize(pct = n()/mean(count)) %>%  -->
<!--   arrange(nodesel, OB, desc(pct)) -->
<!-- ggplot(res, aes(y = pct, x = win, fill = win)) +  -->
<!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--   geom_col() +  -->
<!--   facet_grid(rows = vars(nodesel), cols = vars(OB), scales = "fixed") + -->
<!--   ggtitle("Winner pct") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) -->
<!-- ``` -->


<!-- <!-- There seems to be no effect. Let us have a look at the hard instances (ranges [1,1000] and [1,1000][1,100]) and the winner configurations: --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- res <- datP %>%  --> -->
<!-- <!--   dplyr::filter(grepl("1,1000", rangeC) & !grepl("1001,2000", rangeC)) %>%  --> -->
<!-- <!--   group_by(varsel, OB) %>%  --> -->
<!-- <!--   mutate(count = n(), win = nodesel) %>%  --> -->
<!-- <!--   group_by(varsel, OB, win) %>% summarize(pct = n()/mean(count)) %>%  --> -->
<!-- <!--   arrange(varsel, OB, desc(pct)) --> -->
<!-- <!-- ggplot(res, aes(y = pct, x = win, fill = win)) +  --> -->
<!-- <!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + --> -->
<!-- <!--   geom_col() +  --> -->
<!-- <!--   facet_grid(rows = vars(varsel), cols = vars(OB), scales = "fixed") + --> -->
<!-- <!--   ggtitle("Winner pct") + --> -->
<!-- <!--   theme(legend.position="bottom", legend.title=element_blank()) --> -->
<!-- <!-- ``` --> -->

<!-- <!-- Moreover if we filter further and only look at the sphere generation methods: --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- res <- datP %>%  --> -->
<!-- <!--   dplyr::filter(grepl("sphere", coef) & grepl("1,1000", rangeC) & !grepl("1001,2000", rangeC)) %>%  --> -->
<!-- <!--   group_by(varsel, OB) %>%  --> -->
<!-- <!--   mutate(count = n(), win = nodesel) %>%  --> -->
<!-- <!--   group_by(varsel, OB, win) %>% summarize(pct = n()/mean(count)) %>%  --> -->
<!-- <!--   arrange(varsel, OB, desc(pct)) --> -->
<!-- <!-- ggplot(res, aes(y = pct, x = win, fill = win)) +  --> -->
<!-- <!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + --> -->
<!-- <!--   geom_col() +  --> -->
<!-- <!--   facet_grid(rows = vars(varsel), cols = vars(OB), scales = "fixed") + --> -->
<!-- <!--   ggtitle("Winner pct") + --> -->
<!-- <!--   theme(legend.position="bottom", legend.title=element_blank()) --> -->
<!-- <!-- ``` --> -->


<!-- # Analysis: Research Question 4 (R4) - How are nodes phantomed? -->

<!-- ```{r} -->
<!-- res <- datAll %>% -->
<!--   select(instance, namePrefix, insId, constId, pb, n, coef, rangeC, ratioNDcoef, nodesel, varsel, OB, algConfig, YN, nbinfeas,	pctinfeas, tpsinfeas,	nbopt, pctopt, tpsopt, nbdomi, pctdomi,	avgdomi) %>% -->
<!--   # mutate(pcttpsmisc = 100 - (pcttpsLB + pcttpsdomi + pcttpsUB + pcttpsnodesel + pcttpsvarsel + pcttpsSLUB + pcttpsdomiLUB)) %>% -->
<!--   group_by(pb, coef, nodesel, varsel, OB, algConfig) %>% -->
<!--   nest() -->
<!-- res <- res %>%  -->
<!--   mutate( -->
<!--     meanV = map(data, function(df) { -->
<!--       df %>% summarise_if(is.numeric, mean) -->
<!--     }), -->
<!--   ) %>% unnest(c(meanV), names_sep = "_") -->
<!-- colnames(res) <- str_remove(colnames(res), "meanV_") -->
<!-- res1 <- res %>% pivot_longer(contains("pct")) -->
<!-- ggplot(res1, aes(y = value, x = name, fill = algConfig)) + -->
<!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--   geom_col(position = "dodge") + -->
<!--   facet_grid(rows = vars(pb), cols = vars(coef), scales = "free") + -->
<!--   ggtitle("Relative number of leaf nodes pruned") + ylab("pct") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) +  -->
<!--   scale_fill_algConfig -->

<!-- res1 <- res %>% pivot_longer(contains("nb")) -->
<!-- ggplot(res1, aes(y = value, x = name, fill = algConfig)) + -->
<!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--   geom_col(position = "dodge") + -->
<!--   facet_grid(rows = vars(pb), cols = vars(coef), scales = "free") + -->
<!--   ggtitle("Number of leaf nodes pruned") + ylab("count") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) +  -->
<!--   scale_fill_algConfig -->

<!-- res1 <- res %>% pivot_longer(contains("tps") | contains("avg")) -->
<!-- ggplot(res1, aes(y = value, x = name, fill = algConfig)) + -->
<!--   # stat_summary(fun=mean, geom="line", aes(color = win)) + -->
<!--   geom_col(position = "dodge") + -->
<!--   facet_grid(rows = vars(pb), cols = vars(coef), scales = "free") + -->
<!--   ggtitle("Avg. time to prune a node") + ylab("msec") + -->
<!--   theme(legend.position="bottom", legend.title=element_blank()) +  -->
<!--   scale_fill_algConfig -->
<!-- ``` -->




# Things that are currently not used

Reverse performance plot for the different algorithm configurations are given in Figure \@ref(fig:revPerfPlot).
```{r revPerfPlot, fig.cap="Reverse performance plots for the different problem classes"}
ggplot(datAll %>% 
       group_by(algConfig, pb, n, solved, nodeselVarsel, OB) %>% 
         summarise(count = n()) %>% 
         group_by(algConfig, pb, n, nodeselVarsel, OB) %>% 
         summarise(solv = ifelse(length(count[solved==1]) == 0, 0, count[solved==1]), pct = solv/sum(count))) +
  # geom_col(aes(x=n, y=pct, fill = algConfig, linetype = OB), position = "dodge") +
  geom_step(aes(x=n, y=pct, color = nodeselVarsel, linetype = OB), alpha = 0.75) +
  geom_point(aes(x=n, y=pct, color = nodeselVarsel)) + 
  facet_grid(cols = vars(pb), scales = "free") +
  ggtitle(str_c("Number of instances solved within the time limit given n")) +
  labs(color = "nS | vS:", linetype = "oB:") +
  theme(legend.position="bottom") + #xlab("cpu") +
  scale_color_nodesel_varsel + scale_linetype_ob
```


```{r, fig.asp=1, layout="l-screen-inset"}
plotCPUFacet <- function() {
  datP <- datAll
  tmp <- datP %>% group_by(coef, rangeC) %>% summarize(avg = mean(tpstotal))
  plt <- ggplot(datP, aes(y = tpstotal , x = n, color = algConfig)) +
    stat_summary(fun=mean, geom="line") +
    geom_jitter(width = 0.5, height = 0, size = 0.7) +
    facet_grid(cols = vars(pb), scales = "free") +
    ggtitle(str_c("Cpu time (note scale free)")) +
    theme(legend.position="bottom", legend.title=element_blank()) +
    coord_cartesian(ylim = c(0, 1800)) +
    scale_color_algConfig
  print(plt)
}
ggplotly(plotCPUFacet())
```

```{r, layout="l-screen-inset"}
# datBestCpu <- 
#   datAllConfigs %>% 
#   group_by(algConfig) %>% 
#   summarise(cpu = mean(tpstotal), cpuMax = max(tpstotal), solved = if_else(mean(solved) == 1, T, F)) %>% 
#   arrange(cpu)
# winSeq <- datBestCpu$algConfig
winSeq <- c(winSq, algConfigs[!(algConfigs %in% winSq)])
winAlgConfigSeq <- winSeq
winSeq <- c(str_c("cpu_", winSeq), str_c("ctWin_", winSeq), str_c("nodes_", winSeq), str_c("prune_", winSeq))
winSeq <- winSeq[as.vector(sapply(1:algConfigsN, FUN = function(i) {c(i, i+algConfigsN, i+2*algConfigsN, i+3*algConfigsN)}))]

tmp <- datAll %>% 
  group_by(instance) %>%
  filter(n() == algConfigsN) %>%
  ungroup() 
tmpWin <- datWin %>% 
  filter(instance %in% unique(tmp$instance))


getResGroup <- function(dat, win, ...) {
  datYN <- dat %>% 
    group_by(instance, ...) %>% 
    summarise(YN = max(YN), YNse = max(YNse), YNs = max(YNs)) %>% 
    group_by(...) %>% 
    summarise(YN = mean(YN), YNse = mean(YNse), YNs = mean(YNs)) 
  
  datWinner <- win %>% 
    group_by(..., algConfig) %>%
    summarise(ctWin = n()) %>% 
    full_join(dat %>% distinct(..., algConfig)) %>% 
    replace_na(list(ctWin = 0))

  datResults <- dat %>% 
    group_by(..., algConfig) %>% 
    summarise(ct = n(), cpu = mean(tpstotal), cpuMax = max(tpstotal), cpuMin = min(tpstotal), 
              nodes = mean(nbnodes), nInf = mean(pctinfeas), nOpt = mean(pctopt), nDom = mean(pctdomi),
              dptLeaf = mean(avgdepthT), dptMinLeaf = mean(mindepthT), dptMaxLeaf = mean(maxdepthT),
              solved = min(solved)) %>% 
    full_join(datYN) %>% 
    full_join(datWinner) %>% 
    mutate(cpu = if_else(cpu == min(cpu), str_c(round(cpu, 1), "!"), str_c(round(cpu, 1))),
           ctWin = if_else(ctWin == max(ctWin), str_c(round(ctWin, 0), "!"), str_c(round(ctWin, 0))),
           nodes = if_else(nodes == min(nodes), str_c(round(nodes, 0), "!"), str_c(round(nodes, 0))),) %>% 
    ungroup() %>% 
    mutate(cpu = if_else(solved == 1, 
                         str_c(cpu, " [", round(cpuMin,1), ",", round(cpuMax,1), "]"), 
                         str_c(cpu, "*", " [", round(cpuMin,1), ",", round(cpuMax,1), "]")),
           YN = str_c(round(YN), " (", round(100*YNse/YN), "/", round(100*(YNs-YNse)/YN), "/", round(100*(YN-YNs)/YN), ")"),
           nodes = str_c(nodes, " [", round(dptMinLeaf), ",", round(dptLeaf), ",", round(dptMaxLeaf), "]"),
           prune = str_c("[", round(nInf), ",", round(nOpt), ",", round(nDom), "]")
           ) %>%
    select(-solved, -cpuMin, -cpuMax, -dptMinLeaf, -dptMaxLeaf, -dptLeaf, -nInf, -nOpt, -nDom) %>%
    pivot_wider(names_from = c(algConfig), values_from = c(cpu, nodes, prune, ctWin)) %>%
    select(..., ct, YN, !!winSeq)
  return(datResults)
}
datResRows <- getResGroup(tmp, tmpWin, pb, n)
tabResults <- NULL
for (p in unique(datResRows$pb)) {
  dat1 <- datResRows %>% filter(pb == p)
  dat2 <- getResGroup(tmp, tmpWin, pb) %>% filter(pb == p)
  tabResults  <- bind_rows(tabResults, dat1, dat2)
}

# 
# datYN <- datAll %>% 
#   group_by(instance, pb, n, coef) %>% 
#   summarise(YN = max(YN), YNse = max(YNse), YNs = max(YNs)) %>% 
#   group_by(pb, n, coef) %>% 
#   summarise(YN = mean(YN), YNse = mean(YNse), YNs = mean(YNs)) 
# 
# winSeq <- datWin %>% group_by(algConfig) %>% summarise(cpu = mean(tpstotal)) %>% arrange(cpu) %>% pull(algConfig)
# winSeq <- c(winSeq, algConfigs[!(algConfigs %in% winSeq)])
# winAlgConfigSeq <- winSeq
# winSeq <- c(str_c("cpu_", winSeq), str_c("nodes_", winSeq), str_c("prune_", winSeq))
# winSeq <- winSeq[as.vector(sapply(1:12, FUN = function(i) {c(i,i+12,i+24)}))]
# digits <- c(0,0,rep(c(1,0),12))
# tabResults <- datAll %>% 
#   group_by(pb, n, coef, algConfig) %>% 
#   summarise(cpu = mean(tpstotal), cpuMax = max(tpstotal), cpuMin = min(tpstotal), 
#             nodes = mean(nbnodes), nInf = mean(pctinfeas), nOpt = mean(pctopt), nDom = mean(pctdomi),
#             dptLeaf = mean(avgdepthT), dptMinLeaf = mean(mindepthT), dptMaxLeaf = mean(maxdepthT),
#             solved = min(solved)) %>% 
#   ungroup() %>% 
#   full_join(datYN) %>% 
#   mutate(cpu = if_else(solved == 1, 
#                        str_c(round(cpu, 1), " [", round(cpuMin,1), ",", round(cpuMax,1), "]"), 
#                        str_c(round(cpu, 1), "*", " [", round(cpuMin,1), ",", round(cpuMax,1), "]")),
#          YN = str_c(round(YN), " (", round(100*YNse/YN), "/", round(100*(YNs-YNse)/YN), "/", round(100*(YN-YNs)/YN), ")"),
#          nodes = str_c(round(nodes), " [", round(dptMinLeaf), ",", round(dptLeaf), ",", round(dptMaxLeaf), "]"),
#          prune = str_c("[", round(nInf), ",", round(nOpt), ",", round(nDom), "]")
#          ) %>%
#   select(-solved, -cpuMin, -cpuMax, -dptMinLeaf, -dptMaxLeaf, -dptLeaf, -nInf, -nOpt, -nDom) %>% 
#   pivot_wider(names_from = c(algConfig), values_from = c(cpu, nodes, prune)) %>% 
#   select(pb, n, YN, !!winSeq)

tabResults <- tabResults %>% 
  mutate_at(vars(contains(c("cpu", "win", "nodes"))), ~cell_spec(., bold = if_else(str_detect(., fixed("!")), T, F))) %>% 
  mutate_if(is.character, str_replace_all, pattern = "!", replacement = "")
digits <- c(0,0,0,rep(c(1,0,0,0),algConfigsN))
tabResults %>% 
  select(-pb) %>% 
  kable(
    digits = digits, 
    escape = F,
    col.names = c("n", "#", "YN (se, sne, us)",
                  rep(c("cpu", "win", "nodes (d leaf)", "prune (I/O/D)"), length(winAlgConfigSeq))),
    caption = "Results for each instance group.") %>% 
  kable_styling() %>% 
  add_header_above(c(" " = 3, setNames(rep(4, length(winAlgConfigSeq)), winAlgConfigSeq))) %>% 
  pack_rows("AP", min(which(tabResults$pb == "AP")), max(which(tabResults$pb == "AP"))) %>% 
  pack_rows("KP", min(which(tabResults$pb == "KP")), max(which(tabResults$pb == "KP"))) %>% 
  pack_rows("UFLP", min(which(tabResults$pb == "UFLP")), max(which(tabResults$pb == "UFLP"))) %>% 
  row_spec(c(max(which(tabResults$pb == "AP")), 
             max(which(tabResults$pb == "KP")), 
             max(which(tabResults$pb == "UFLP"))), italic = T, background = "lightgrey") %>% 
  scroll_box(width = "100%")
```

```{r}
datAll %>% 
  group_by(instance) %>%
  filter(n() == algConfigsN) %>%
  ungroup() %>% 
  group_by(n, pb, OB, nodeselVarsel) %>% 
  summarise(node = mean(nbnodes)) %>% 
  ggplot(aes(x = n, y = node, color = OB, linetype = nodeselVarsel)) + 
  geom_line(alpha = 0.75) +
  # geom_point(alpha = 0.75) +
  facet_grid(cols = vars(pb), scales = "free") + 
  ggtitle(str_c("Average branching tree size.")) +
  labs(color = "oB:", linetype = "nS:") +
  scale_color_ob + scale_linetype_nodesel_varsel +
  theme(legend.position="bottom") + xlab("n") + ylab("tree size") 
  # coord_cartesian(expand = FALSE, ylim = c(0, NA), xlim = c(-10, 1797)) 
```

## Detailed results for each instance

Detailed results for each instance can be generated using `instance.Rmd`. The report is already generated for some of the instances (see links in the table with input statistics). Some instances that might be of interest:

```{r}
tmp <- datAll %>% group_by(instance) %>% summarise_at(vars(contains(c("YN", "total", "solved"))), list(mean = mean, sd = sd, max = max), na.rm = TRUE)
```

* Instances with lowest number of nondominated points: `r toLink(tmp %>% top_n(-3, YN_max) %>% slice(1:3) %>% pull(instance))`
* Instances with highest number of nondominated points (solved): `r toLink(tmp %>% filter(solved_max == 1) %>% top_n(3, YN_mean) %>% slice(1:3) %>% pull(instance))`
* Instances with lowest unsupported nondominated points percentage: `r toLink(tmp %>% top_n(-3, YNusRatio_max) %>% slice(1:3)%>% pull(instance))`
* Instances with highest unsupported nondominated points percentage: `r toLink(tmp %>% top_n(3, YNusRatio_max) %>% slice(1:3)%>% pull(instance))`
* Instances with highest supported non-extreme nondominated points percentage: `r toLink(tmp %>% top_n(3, YNsneRatio_max) %>% arrange(YNsneRatio_max) %>%  slice(1:3) %>% pull(instance))` 
* Instances with highest variance in cpu time: `r toLink(tmp %>% top_n(3, tpstotal_sd) %>% slice(1:3) %>% pull(instance))`
